setwd("C:/Users/rians/OneDrive/Área de Trabalho/analise_dados_mortalidade/project")
install.packages("remotes")
remotes::install_github("rfsaldanha/microdatasus", force=TRUE)
library(microdatasus)
remotes::install_github("rfsaldanha/microdatasus", force=TRUE)
library(microdatasus)
install.packages("remotes")
install.packages("remotes")
remotes::install_github("rfsaldanha/microdatasus")
library(microdatasus)
remotes::install_github("rfsaldanha/microdatasus", force = TRUE)
install.packages('read.dbc')
library(read.dbc)
install.packages('read.dbc')
devtools::install_github("danicat/read.dbc")
devtools::install_github("danicat/read.dbc")
remotes::install_github("danicat/read.dbc")
install.packages('read.dbc')
##########################
# BAIXA OS DADOS
##########################
install.packages("Rtools")
install.packages("devtools")
devtools::install_github("danicat/read.dbc")
remotes::install_github("rfsaldanha/microdatasus", force = TRUE)
library(microdatasus)
pkgbuild::check_build_tools(debug = TRUE)
library(read.dbc)
pkgbuild::check_build_tools(debug = TRUE)
remotes::install_github("rfsaldanha/microdatasus", force = TRUE)
library(microdatasus)
devtools::install_github("danicat/read.dbc")
install.packages("C:/Users/rians/Downloads/read.dbc_1.0.5.tar.gz", repos = NULL, type = "source")
remotes::install_github("rfsaldanha/microdatasus", force = TRUE)
library(microdatasus)
dados <- fetch_datasus(year_start = 2020, year_end = 2020, uf = "SP", information_system = "SIM-DO")
# Posix não aguenta este processamento
dados <-process_sim(dados)
# Posix não aguenta este processamento
dados <-process_sim(dados)
sumary(dados$SEXO)
str(dados$SEXO)
library(dplyr)
library(caret) # calcula matriz de confusão
library(psych)
library(naivebayes) # executa o algoritmo naive bayes
library(ggplot2) # Para análise exploratória
library(pROC) # Para curva ROC
dados <- fetch_datasus(year_start = 2020, year_end = 2020, uf = "SP", information_system = "SIM-DO")
# Posix não aguenta este processamento
dados <-process_sim(dados)
save.image("C:/Users/rians/OneDrive/Área de Trabalho/analise_dados_mortalidade/project/save_04-06.RData")
View(dados)
View(dados)
View(dados)
View(dados)
View(dados)
View(dados)
View(dados)
View(dados)
View(dados)
View(dados)
View(dados)
# Analise exploratória do SEXO
plot(dados$SEXO)
# Verifica outlier
boxplot(dados$IDADE)
dados <- dados%>%simple(10000);
dados <- dados%>%simple(10000)%>%
collect();
dados <- dados%>%simple(10000)%>%
collect()
dados <- select(dados)%>%simple(10000)
dados <- dados%>%sample_n(10000)
# Verifica outlier
boxplot(dados$IDADE)
# Analise exploratória do SEXO
plot(dados$SEXO)
# Gera o plot das colunas idade e racacor, com amostra de 100
select(dados, SEXO, RACACOR) %>%
sample_n(100) %>%
collect() %>%
plot()
dados$ESTCIV
# Analise exploratória do SEXO
plot(as.factor(dados$SEXO))
# Análise exploatória da Idade
plot(s.factor(dados$IDADEanos))
# Análise exploatória da Idade
plot(as.factor(dados$IDADEanos))
# Análise exploratória do estado cívil
plot(as.factor(dados$ESTCIV))
# Verifica outlier
boxplot(dados$IDADEanos)
# Verifica outlier
boxplot(dados$IDADE)
dados<-dados%>%
mutate(faixa_idade = ifelse(as.numeric(as.character(IDADEanos)) < 20, "< 20", ifelse(as.numeric(as.character(IDADEanos)) >= 20 & as.numeric(as.character(IDADEanos)) < 30, ">=20 e < 30", ifelse(as.numeric(as.character(IDADEanos)) >= 30 & as.numeric(as.character(IDADEanos)) < 40, ">=30 e < 40", ">=40"))))
plot(dados$faixa_idade)
plot(as.factor(dados$faixa_idade))
View(dados)
install.packages("leaflet")
library(leaflet)
m <- leaflet() %>%
addTiles() %>%  # Add default OpenStreetMap map tiles
addMarkers(lng=174.768, lat=-36.852, popup="The birthplace of R")
m  # Print the map
m <- leaflet() %>%
addTiles() %>%  # Add default OpenStreetMap map tiles
addMarkers(lng=-46.53087, lat=-49.75142, popup="The birthplace of R")
m  # Print the map
m <- leaflet() %>%
addTiles() %>%  # Add default OpenStreetMap map tiles
addMarkers(lng=-46.53087, lat=-23.65751, popup="The birthplace of R")
m  # Print the map
m <- leaflet()
m <- addTiles(m)
m<-dados%>%addMarkers(m, lng=as.numeric(dados$munResLon), lat=as.numeric(dados$munResLat) popup="The birthplace of R")
for (i in dados){
m<-addMarkers(m, lng=as.numeric(i$munResLon), lat=as.numeric(i$munResLat) popup="The birthplace of R")
for (i in dados){
i
}
for (i in dados){
str(i)
}
length(dados)
count(dados)
str(i)
for (i in 1:count(dados)){
str(i)
}
for (j in 1:count(dados)){
str(j)
}
1:count(dados))
1:count(dados)
count(dados)
1:count(dados)[0]
1:count(dados)[1]
count(dados)
count(dados).n
count(dados)['n']
count(dados)['n']
count(dados)['n'][1]
count(dados)['n'][1]
1:count(dados)['n'][1]
for(i in dados) {                       # Run for-loop
loop_index_1 <- loop_index_1 + 1
print(loop_index_1)                    # Print index
}
loop_index_1 <- 0
for(i in dados) {                       # Run for-loop
loop_index_1 <- loop_index_1 + 1
print(loop_index_1)                    # Print index
}
loop_index_1 <- 0
while (loop_index_1 < count(dados)){                       # Run for-loop
loop_index_1 <- loop_index_1 + 1
print(loop_index_1)                    # Print index
}
loop_index_1 <- 0
while (loop_index_1 < count(dados)){                       # Run for-loop
loop_index_1 <- loop_index_1 + 1
print(loop_index_1)
print(dados[loop_index_1].munResLon)# Print index
loop_index_1 <- 0
while (loop_index_1 < count(dados)){                       # Run for-loop
loop_index_1 <- loop_index_1 + 1
print(loop_index_1)
print(dados.munResLon[loop_index_1])
}
loop_index_1 <- 0
while (loop_index_1 < count(dados)){                       # Run for-loop
loop_index_1 <- loop_index_1 + 1
print(loop_index_1)
str(dados.munResLon[loop_index_1])
}
loop_index_1 <- 0
while (loop_index_1 < count(dados)){                       # Run for-loop
loop_index_1 <- loop_index_1 + 1
print(loop_index_1)
str(dados[loop_index_1].munResLon)
View(dados)
dados$munResLon[1]
loop_index_1 <- 0
while (loop_index_1 < count(dados)){                       # Run for-loop
loop_index_1 <- loop_index_1 + 1
print(loop_index_1)
str(as.numeric(dados$munResLon[loop_index_1]))
}
loop_index_1 <- 0
while (loop_index_1 < count(dados)){                       # Run for-loop
loop_index_1 <- loop_index_1 + 1
m <- addMarkers(m,
lng=as.numeric(dados$munResLon[loop_index_1]),
lat=as.numeric(dados$munResLat[loop_index_1]),
popup=as.numeric(dados$munResNome[loop_index_1]))
}
m
plot(as.factor(dados$munResNome))
dados <- subset(dados, select = -c(CONTADOR, CODIFICADO, ESTABDESCR, FONTESINF, NUDIASOBIN, FONTES, MORTEPARTO, NUDIASINF, STCODIFICA, TPNIVELINV, VERSAOSCB, VERSAOSIST))
save.image("C:/Users/rians/OneDrive/Área de Trabalho/analise_dados_mortalidade/project/save_04-06.RData")
library(ggplot2)
library(dplyr)
library(DAAG)
install.packages('DAAG')
library(DAAG)
data("cars")
View(cars)
ggplot(cars, aes(speed,dist))+
geom_point()
ggplot(cars, aes(price,dist))+
geom_point()
View(cars)
View(cars)
ggplot(cars, aes(Price,dist))+
geom_point()
ggplot(cars, aes(Price,dist))
ggplot(cars, aes(Price,Mileage))+
geom_point()
ggplot(cars, aes(Price,Sedan))+
geom_point()
ggplot(cars, aes(Price,sedan))+
geom_point()
#Podemos obter a reta de regressão
stop_dist_model = lm(Price ~ Sedan, data = cars)
#Podemos obter a reta de regressão
stop_dist_model = lm(Price ~ sedan, data = cars)
stop_dist_model
stop_dist_model$coefficients
stop_dist_model$residuals
summary(stop_dist_model)
#Predição de valores novos
predict(stop_dist_model, newdata = data.frame(speed = 8))
#Box plot com ggplot
ggplot(cars, aes(y = Price)) +
geom_boxplot()
ggplot(cars, aes(y = sedan)) +
geom_boxplot()
ggplot(cars, aes(y = Mileage)) +
geom_boxplot()
View(cars)
data("cars")
#Distribuição é normal?
shapiro.test(cars$Price)
##########################
# ANALISE IMPLICITA
##########################
# Regressão
##########################
#Box plot com ggplot
ggplot(cars, aes(y = Price)) +
geom_boxplot()
##########################
# ANALISE IMPLICITA
##########################
# Regressão
##########################
#Box plot com ggplot
ggplot(dados, aes(y = IDADEanos)) +
geom_boxplot()
ggplot(cars, aes(Price,sedan))+
geom_point()
ggplot(cars, aes(Price,Cylinder))+
geom_point()
#Podemos obter a reta de regressão
stop_dist_model = lm(Price ~ Cylinder, data = cars)
stop_dist_model
stop_dist_model$coefficients
stop_dist_model$residuals
summary(stop_dist_model)
#Predição de valores novos
predict(stop_dist_model, newdata = data.frame(Cylinder = 4))
#Para múltiplos valores
predict(stop_dist_model, newdata = data.frame(speed = c(2, 4, 6)))
#Para múltiplos valores
predict(stop_dist_model, newdata = data.frame(Cylinder = c(2, 4, 6)))
#Para múltiplos valores
predict(stop_dist_model, newdata = data.frame(Cylinder = c(2, 4, 6, 8)))
ggplot(cars, aes(y = Cylinder)) +
geom_boxplot()
#Distribuição é normal?
shapiro.test(cars$Price)
shapiro.test(cars$Cylinder)
#Verificando a correlação
cor(cars$Price,cars$Cylinder)
modelo_cars <- lm(Cylinder ~ Price, data=cars)
summary(modelo_cars)
#Criando e testando o modelo
#Etapa 1
set.seed(100)
train_linha_cars <- sample(1:nrow(cars), 0.8*nrow(cars))  # índice da linha dos dados de treinamento
train_dado_cars <- cars[train_linha_cars, ]  # dados do modelo de treinamento
test_dado_cars  <- cars[-train_linha_cars, ]
# Etapa 2: construir o modelo de treinamento dos dados
lm_model_cars <- lm(Cylinder ~ Price, data=train_dado_cars)  # construção do modelo
dist_pred_cars <- predict(lm_model_cars, test_dado_cars)  # predição da distância
#Etapa 3 - análise do modelo
#verificar se p-value é significativo e comparar r-squared com o modelo original
summary (lm_model_cars)
#Etapa 4: calcular a precisão da previsão e as taxas de erro
pred_real_cars <- data.frame(cbind(real_cars=test_dado_cars$Cylinder, predicao_cars=dist_pred_cars))
acuracia_corr_cars <- cor(pred_real_cars)
head(pred_real_cars)
#taxas de erro
min_max_acuracia_cars <- mean(apply(pred_real_cars, 1, min) / apply(pred_real_cars, 1, max))
mape_cars <- mean(abs((pred_real_cars$predicao - pred_real_cars$real))/pred_real_cars$real)
mape_cars
head(pred_real_cars)
library(tidyverse)
library(dplyr)
library(recipes)
library(caret)
library(pROC)
library(recipes)
str(titanic)
data("Titanic")
str(titanic)
